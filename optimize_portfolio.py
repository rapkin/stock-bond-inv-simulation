#!/usr/bin/env python3
"""
Portfolio Optimization Script
–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Å–∏–º—É–ª—è—Ü—ñ–π.

–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Modern Portfolio Theory (MPT) –¥–ª—è –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è
–æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –≤–∞–≥ –∞–∫—Ç–∏–≤—ñ–≤ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∫–æ—Ä–µ–ª—è—Ü—ñ–π.
"""

import argparse
from pathlib import Path

import numpy as np
import pandas as pd
from scipy.optimize import minimize


def load_returns_data(results_dir: Path) -> pd.DataFrame:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–µ–Ω–Ω—ñ –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –∑ —É—Å—ñ—Ö —Å–∏–º—É–ª—è—Ü—ñ–π.

    Returns:
        DataFrame –∑ –¥–µ–Ω–Ω–∏–º–∏ –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—è–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç—ñ–∫–µ—Ä–∞
    """
    returns_dict = {}

    for sim_dir in results_dir.iterdir():
        if not sim_dir.is_dir():
            continue

        data_file = sim_dir / 'simulation_data.csv'
        metrics_file = sim_dir / 'metrics.csv'

        if not data_file.exists() or not metrics_file.exists():
            continue

        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—ñ–∫–µ—Ä –∑ –º–µ—Ç—Ä–∏–∫
            metrics = pd.read_csv(metrics_file)
            ticker = metrics['ticker'].iloc[0]

            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –ø–æ—Ä—Ç—Ñ–µ–ª—è
            data = pd.read_csv(data_file, parse_dates=['date'])
            data = data.set_index('date')

            # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ –¥–µ–Ω–Ω—ñ –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –ø–æ—Ä—Ç—Ñ–µ–ª—è
            portfolio_values = data['portfolio_value']
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –Ω—É–ª—å–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            portfolio_values = portfolio_values[portfolio_values > 0]
            returns = portfolio_values.pct_change().dropna()

            # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ—Å–∫—ñ–Ω—á–µ–Ω–Ω—ñ —Ç–∞ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
            returns = returns.replace([np.inf, -np.inf], np.nan).dropna()
            returns = returns[returns.abs() < 1]  # –í–∏–¥–∞–ª—è—î–º–æ >100% –¥–µ–Ω–Ω—ñ –∑–º—ñ–Ω–∏

            if len(returns) > 100:  # –ú—ñ–Ω—ñ–º—É–º 100 –¥–Ω—ñ–≤ –¥–∞–Ω–∏—Ö
                returns_dict[ticker] = returns

        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {sim_dir.name}: {e}")

    if not returns_dict:
        return pd.DataFrame()

    # –û–±'—î–¥–Ω—É—î–º–æ –≤ –æ–¥–∏–Ω DataFrame
    returns_df = pd.DataFrame(returns_dict)

    # –ó–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –¥–∞—Ç–∏ –¥–µ —î –¥–∞–Ω—ñ –¥–ª—è –≤—Å—ñ—Ö –∞–∫—Ç–∏–≤—ñ–≤
    returns_df = returns_df.dropna()

    return returns_df


def load_metrics(results_dir: Path) -> pd.DataFrame:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –∑ comparison.csv –∞–±–æ –∑ —Ñ–∞–π–ª—ñ–≤ –º–µ—Ç—Ä–∏–∫."""
    comparison_file = results_dir / 'comparison.csv'

    if comparison_file.exists():
        return pd.read_csv(comparison_file)

    # –Ø–∫—â–æ –Ω–µ–º–∞—î comparison.csv, –∑–±–∏—Ä–∞—î–º–æ –∑ –æ–∫—Ä–µ–º–∏—Ö —Ñ–∞–π–ª—ñ–≤
    metrics_list = []
    for metrics_file in results_dir.glob('*/metrics.csv'):
        try:
            df = pd.read_csv(metrics_file)
            metrics_list.append(df)
        except:
            pass

    if metrics_list:
        return pd.concat(metrics_list, ignore_index=True)

    return pd.DataFrame()


def calculate_portfolio_stats(weights: np.ndarray,
                               mean_returns: np.ndarray,
                               cov_matrix: np.ndarray) -> tuple:
    """–†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –æ—á—ñ–∫—É–≤–∞–Ω—É –¥–æ—Ö—ñ–¥–Ω—ñ—Å—Ç—å —Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è."""
    portfolio_return = np.sum(mean_returns * weights) * 252  # –†—ñ—á–Ω–∞
    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * 252, weights)))
    return portfolio_return, portfolio_volatility


def negative_sharpe(weights: np.ndarray,
                    mean_returns: np.ndarray,
                    cov_matrix: np.ndarray,
                    risk_free_rate: float = 0.02) -> float:
    """–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π Sharpe Ratio (–¥–ª—è –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó)."""
    p_return, p_volatility = calculate_portfolio_stats(weights, mean_returns, cov_matrix)
    return -(p_return - risk_free_rate) / p_volatility


def portfolio_volatility(weights: np.ndarray,
                         mean_returns: np.ndarray,
                         cov_matrix: np.ndarray) -> float:
    """–í–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è (–¥–ª—è –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó)."""
    _, p_volatility = calculate_portfolio_stats(weights, mean_returns, cov_matrix)
    return p_volatility


def optimize_portfolio(returns_df: pd.DataFrame,
                       metrics_df: pd.DataFrame,
                       optimization_target: str = 'sharpe',
                       max_weight: float = 0.4,
                       min_weight: float = 0.0) -> dict:
    """
    –û–ø—Ç–∏–º—ñ–∑—É–≤–∞—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—å.

    Args:
        returns_df: DataFrame –∑ –¥–µ–Ω–Ω–∏–º–∏ –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—è–º–∏
        metrics_df: DataFrame –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        optimization_target: 'sharpe' (–º–∞–∫—Å Sharpe) –∞–±–æ 'min_var' (–º—ñ–Ω –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å)
        max_weight: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞ –æ–¥–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É
        min_weight: –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞ –æ–¥–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É

    Returns:
        dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
    """
    tickers = returns_df.columns.tolist()
    n_assets = len(tickers)

    # –°–µ—Ä–µ–¥–Ω—ñ –¥–æ—Ö—ñ–¥–Ω–æ—Å—Ç—ñ —Ç–∞ –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
    mean_returns = returns_df.mean().values
    cov_matrix = returns_df.cov().values

    # –ü–æ—á–∞—Ç–∫–æ–≤—ñ –≤–∞–≥–∏ (—Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª)
    initial_weights = np.array([1.0 / n_assets] * n_assets)

    # –û–±–º–µ–∂–µ–Ω–Ω—è
    constraints = [
        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}  # –°—É–º–∞ –≤–∞–≥ = 1
    ]

    # –ú–µ–∂—ñ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É
    bounds = tuple((min_weight, max_weight) for _ in range(n_assets))

    # –í–∏–±—ñ—Ä —Ü—ñ–ª—å–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
    if optimization_target == 'sharpe':
        objective = negative_sharpe
    else:  # min_var
        objective = portfolio_volatility

    # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
    result = minimize(
        objective,
        initial_weights,
        args=(mean_returns, cov_matrix),
        method='SLSQP',
        bounds=bounds,
        constraints=constraints
    )

    if not result.success:
        print(f"–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è: –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –Ω–µ –∑–±—ñ–≥–ª–∞—Å—å - {result.message}")

    optimal_weights = result.x

    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    opt_return, opt_volatility = calculate_portfolio_stats(
        optimal_weights, mean_returns, cov_matrix
    )
    opt_sharpe = (opt_return - 0.02) / opt_volatility

    # –ó–≤–∞–∂–µ–Ω–∏–π max drawdown
    if 'max_drawdown_pct' in metrics_df.columns:
        ticker_dd = metrics_df.set_index('ticker')['max_drawdown_pct'].to_dict()
        weighted_dd = sum(
            optimal_weights[i] * ticker_dd.get(t, 0)
            for i, t in enumerate(tickers)
        )
    else:
        weighted_dd = None

    return {
        'tickers': tickers,
        'weights': optimal_weights,
        'expected_return': opt_return,
        'volatility': opt_volatility,
        'sharpe_ratio': opt_sharpe,
        'weighted_max_drawdown': weighted_dd,
        'correlation_matrix': pd.DataFrame(
            returns_df.corr(),
            index=tickers,
            columns=tickers
        ),
        'mean_returns': mean_returns,
        'cov_matrix': cov_matrix,
    }


def generate_efficient_frontier(returns_df: pd.DataFrame,
                                n_points: int = 50) -> pd.DataFrame:
    """–ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ç–æ—á–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—ó –≥—Ä–∞–Ω–∏—Ü—ñ."""
    mean_returns = returns_df.mean().values
    cov_matrix = returns_df.cov().values
    n_assets = len(returns_df.columns)

    # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –º—ñ–Ω —Ç–∞ –º–∞–∫—Å –¥–æ—Ö—ñ–¥–Ω—ñ—Å—Ç—å
    min_ret_result = minimize(
        lambda w: -np.sum(mean_returns * w) * 252,
        np.array([1.0 / n_assets] * n_assets),
        method='SLSQP',
        bounds=tuple((0, 1) for _ in range(n_assets)),
        constraints=[{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
    )

    max_ret_result = minimize(
        lambda w: np.sum(mean_returns * w) * 252,
        np.array([1.0 / n_assets] * n_assets),
        method='SLSQP',
        bounds=tuple((0, 1) for _ in range(n_assets)),
        constraints=[{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
    )

    min_return = -min_ret_result.fun
    max_return = -max_ret_result.fun

    target_returns = np.linspace(min_return, max_return, n_points)
    frontier_points = []

    for target in target_returns:
        constraints = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},
            {'type': 'eq', 'fun': lambda w, t=target: np.sum(mean_returns * w) * 252 - t}
        ]

        result = minimize(
            portfolio_volatility,
            np.array([1.0 / n_assets] * n_assets),
            args=(mean_returns, cov_matrix),
            method='SLSQP',
            bounds=tuple((0, 1) for _ in range(n_assets)),
            constraints=constraints
        )

        if result.success:
            vol = portfolio_volatility(result.x, mean_returns, cov_matrix)
            frontier_points.append({
                'return': target,
                'volatility': vol,
                'sharpe': (target - 0.02) / vol
            })

    return pd.DataFrame(frontier_points)


def print_optimization_results(results: dict, metrics_df: pd.DataFrame):
    """–í–∏–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó."""
    print("\n" + "=" * 80)
    print("–û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–Ø –ü–û–†–¢–§–ï–õ–Ø")
    print("=" * 80)

    # –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è
    print("\nüìä –ö–û–†–ï–õ–Ø–¶–Ü–ô–ù–ê –ú–ê–¢–†–ò–¶–Ø:")
    print("-" * 80)
    corr = results['correlation_matrix']
    pd.set_option('display.float_format', lambda x: f'{x:.2f}')
    print(corr.to_string())

    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ñ –≤–∞–≥–∏
    print("\n" + "=" * 80)
    print("üéØ –û–ü–¢–ò–ú–ê–õ–¨–ù–ò–ô –ü–û–†–¢–§–ï–õ–¨ (Maximum Sharpe Ratio)")
    print("=" * 80)

    print("\n–†–æ–∑–ø–æ–¥—ñ–ª –∞–∫—Ç–∏–≤—ñ–≤:")
    print("-" * 50)

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –≤–∞–≥–æ—é
    sorted_idx = np.argsort(results['weights'])[::-1]

    for idx in sorted_idx:
        ticker = results['tickers'][idx]
        weight = results['weights'][idx]
        if weight > 0.001:  # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ >0.1%
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –º–µ—Ç—Ä–∏–∫–∏ —Ç—ñ–∫–µ—Ä–∞
            ticker_metrics = metrics_df[metrics_df['ticker'] == ticker]
            if not ticker_metrics.empty:
                ret = ticker_metrics['total_return_pct'].iloc[0]
                dd = ticker_metrics['max_drawdown_pct'].iloc[0]
                print(f"  {ticker:12} {weight*100:6.1f}%   (Return: {ret:6.1f}%, Max DD: {dd:6.1f}%)")
            else:
                print(f"  {ticker:12} {weight*100:6.1f}%")

    print("-" * 50)
    print(f"  {'TOTAL':12} {sum(results['weights'])*100:6.1f}%")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    print("\nüìà –û–ß–Ü–ö–£–í–ê–ù–Ü –ü–û–ö–ê–ó–ù–ò–ö–ò –ü–û–†–¢–§–ï–õ–Ø:")
    print("-" * 50)
    print(f"  –û—á—ñ–∫—É–≤–∞–Ω–∞ —Ä—ñ—á–Ω–∞ –¥–æ—Ö—ñ–¥–Ω—ñ—Å—Ç—å: {results['expected_return']*100:6.2f}%")
    print(f"  –†—ñ—á–Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å:        {results['volatility']*100:6.2f}%")
    print(f"  Sharpe Ratio:               {results['sharpe_ratio']:6.2f}")
    if results['weighted_max_drawdown']:
        print(f"  –ó–≤–∞–∂–µ–Ω–∏–π Max Drawdown:      {results['weighted_max_drawdown']:6.2f}%")

    print("=" * 80)


def print_equal_weight_comparison(returns_df: pd.DataFrame,
                                   optimal_results: dict):
    """–ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –∑ —Ä—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–º —Ä–æ–∑–ø–æ–¥—ñ–ª–æ–º."""
    n_assets = len(returns_df.columns)
    equal_weights = np.array([1.0 / n_assets] * n_assets)

    mean_returns = returns_df.mean().values
    cov_matrix = returns_df.cov().values

    eq_return, eq_volatility = calculate_portfolio_stats(
        equal_weights, mean_returns, cov_matrix
    )
    eq_sharpe = (eq_return - 0.02) / eq_volatility

    print("\nüìä –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ó –†–Ü–í–ù–û–ú–Ü–†–ù–ò–ú –†–û–ó–ü–û–î–Ü–õ–û–ú:")
    print("-" * 60)
    print(f"{'–ú–µ—Ç—Ä–∏–∫–∞':<25} {'–†—ñ–≤–Ω–æ–º—ñ—Ä–Ω–∏–π':>15} {'–û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π':>15}")
    print("-" * 60)
    print(f"{'–û—á—ñ–∫—É–≤–∞–Ω–∞ –¥–æ—Ö—ñ–¥–Ω—ñ—Å—Ç—å':<25} {eq_return*100:>14.2f}% {optimal_results['expected_return']*100:>14.2f}%")
    print(f"{'–í–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å':<25} {eq_volatility*100:>14.2f}% {optimal_results['volatility']*100:>14.2f}%")
    print(f"{'Sharpe Ratio':<25} {eq_sharpe:>15.2f} {optimal_results['sharpe_ratio']:>15.2f}")
    print("-" * 60)

    improvement = (optimal_results['sharpe_ratio'] / eq_sharpe - 1) * 100
    print(f"\n‚ú® –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è Sharpe Ratio: {improvement:+.1f}%")


def main():
    parser = argparse.ArgumentParser(
        description='–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Å–∏–º—É–ª—è—Ü—ñ–π',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–∫–ª–∞–¥–∏:
  python optimize_portfolio.py
  python optimize_portfolio.py --max-weight 0.3
  python optimize_portfolio.py --target min_var
        """
    )

    parser.add_argument(
        '--dir', '-d',
        type=str,
        default='./simulation_results',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–º—É–ª—è—Ü—ñ–π'
    )

    parser.add_argument(
        '--target', '-t',
        type=str,
        default='sharpe',
        choices=['sharpe', 'min_var'],
        help='–¶—ñ–ª—å –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó: sharpe (–º–∞–∫—Å Sharpe) –∞–±–æ min_var (–º—ñ–Ω –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å)'
    )

    parser.add_argument(
        '--max-weight',
        type=float,
        default=0.40,
        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞ –æ–¥–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: 0.40)'
    )

    parser.add_argument(
        '--min-weight',
        type=float,
        default=0.0,
        help='–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –≤–∞–≥–∞ –æ–¥–Ω–æ–≥–æ –∞–∫—Ç–∏–≤—É (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: 0.0)'
    )

    args = parser.parse_args()

    results_dir = Path(args.dir)

    if not results_dir.exists():
        print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è {results_dir} –Ω–µ —ñ—Å–Ω—É—î")
        return

    print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
    returns_df = load_returns_data(results_dir)
    metrics_df = load_metrics(results_dir)

    if returns_df.empty:
        print("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–∏—Ö –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó")
        return

    print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(returns_df.columns)} –∞–∫—Ç–∏–≤—ñ–≤: {', '.join(returns_df.columns)}")
    print(f"–ü–µ—Ä—ñ–æ–¥: {len(returns_df)} —Ç–æ—Ä–≥–æ–≤–∏—Ö –¥–Ω—ñ–≤")

    # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
    print(f"\n–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—Ç—Ñ–µ–ª—è (—Ü—ñ–ª—å: {'Maximum Sharpe' if args.target == 'sharpe' else 'Minimum Variance'})...")

    results = optimize_portfolio(
        returns_df,
        metrics_df,
        optimization_target=args.target,
        max_weight=args.max_weight,
        min_weight=args.min_weight
    )

    # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    print_optimization_results(results, metrics_df)
    print_equal_weight_comparison(returns_df, results)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    output_file = results_dir / 'optimal_portfolio.csv'
    pd.DataFrame({
        'ticker': results['tickers'],
        'weight': results['weights'],
        'weight_pct': results['weights'] * 100
    }).to_csv(output_file, index=False)
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {output_file}")


if __name__ == '__main__':
    main()
